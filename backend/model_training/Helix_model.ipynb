{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcmxuNWl613n",
        "outputId": "40f46ba7-e064-4156-8cf4-30d2d3387373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (26.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.33.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.78.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.3.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (12.1.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Install TensorFlow if not already installed (uncomment if needed)\n",
        "# This cell sets up the environment by installing TensorFlow and importing all necessary libraries\n",
        "# for building, training, and evaluating a neural network model.\n",
        "!pip install tensorflow\n",
        "\n",
        "# Core TensorFlow library\n",
        "import tensorflow as tf\n",
        "# Pandas for data manipulation and analysis\n",
        "import pandas as pd\n",
        "# Keras sequential model API\n",
        "from tensorflow.keras import Sequential\n",
        "# Keras layers for building the neural network\n",
        "from tensorflow.keras.layers import Normalization, Dense, InputLayer\n",
        "# Keras functional API for model creation\n",
        "from tensorflow.keras import Input\n",
        "# Keras Model class for functional API\n",
        "from tensorflow.keras.models import Model\n",
        "# Metric for evaluating regression models\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "# Optimizer for training the neural network\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Matplotlib for plotting and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "# NumPy for numerical operations\n",
        "import numpy as np\n",
        "# Function to load a saved Keras model\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "WUwVmZwR9ZPI",
        "outputId": "7a05d4b2-a2f8-4a3b-8591-dec54ca59a98"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset_csv"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-967ddd1c-7a0f-44e9-90a8-d9e6949d7946\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>spo2</th>\n",
              "      <th>bpm</th>\n",
              "      <th>temp</th>\n",
              "      <th>sbp</th>\n",
              "      <th>dbp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>95.702046</td>\n",
              "      <td>60</td>\n",
              "      <td>36.861707</td>\n",
              "      <td>124</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "      <td>96.689413</td>\n",
              "      <td>63</td>\n",
              "      <td>36.511633</td>\n",
              "      <td>126</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>98.508265</td>\n",
              "      <td>63</td>\n",
              "      <td>37.052049</td>\n",
              "      <td>131</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>95.011801</td>\n",
              "      <td>99</td>\n",
              "      <td>36.654747</td>\n",
              "      <td>118</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>98.623792</td>\n",
              "      <td>69</td>\n",
              "      <td>36.975098</td>\n",
              "      <td>138</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200015</th>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>95.357470</td>\n",
              "      <td>87</td>\n",
              "      <td>37.058905</td>\n",
              "      <td>120</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200016</th>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "      <td>99.340786</td>\n",
              "      <td>76</td>\n",
              "      <td>36.463631</td>\n",
              "      <td>131</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200017</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>98.120530</td>\n",
              "      <td>81</td>\n",
              "      <td>36.665477</td>\n",
              "      <td>124</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200018</th>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>95.362426</td>\n",
              "      <td>83</td>\n",
              "      <td>37.019873</td>\n",
              "      <td>125</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200019</th>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>99.523058</td>\n",
              "      <td>69</td>\n",
              "      <td>37.012931</td>\n",
              "      <td>133</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200020 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-967ddd1c-7a0f-44e9-90a8-d9e6949d7946')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-967ddd1c-7a0f-44e9-90a8-d9e6949d7946 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-967ddd1c-7a0f-44e9-90a8-d9e6949d7946');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_fb727fc7-8755-4f88-b62b-508eafed2c6d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset_csv')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fb727fc7-8755-4f88-b62b-508eafed2c6d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset_csv');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        age  gender       spo2  bpm       temp  sbp  dbp\n",
              "0        37       0  95.702046   60  36.861707  124   86\n",
              "1        77       1  96.689413   63  36.511633  126   84\n",
              "2        68       0  98.508265   63  37.052049  131   78\n",
              "3        41       0  95.011801   99  36.654747  118   72\n",
              "4        25       0  98.623792   69  36.975098  138   76\n",
              "...     ...     ...        ...  ...        ...  ...  ...\n",
              "200015   75       1  95.357470   87  37.058905  120   84\n",
              "200016   76       1  99.340786   76  36.463631  131   89\n",
              "200017   18       0  98.120530   81  36.665477  124   89\n",
              "200018   66       0  95.362426   83  37.019873  125   86\n",
              "200019   67       0  99.523058   69  37.012931  133   78\n",
              "\n",
              "[200020 rows x 7 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset from 'dataset.csv' into a pandas DataFrame\n",
        "dataset_csv = pd.read_csv(\"dataset.csv\", delimiter=\",\")\n",
        "# Display the first few rows of the loaded dataset\n",
        "dataset_csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGcpauTX9eiT",
        "outputId": "b01b8e41-6c78-495d-deac-38163f97f57d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[49.          0.         96.38854088 60.         37.18740341]\n",
            " [20.          0.         95.01649599 80.         36.92634001]\n",
            " [42.          0.         96.32399284 86.         36.48293986]\n",
            " ...\n",
            " [83.          1.         95.49267851 90.         36.06983116]\n",
            " [19.          1.         95.25375571 68.         37.36552867]\n",
            " [47.          0.         98.72067605 71.         36.64796452]], shape=(120012, 5), dtype=float64)\n",
            "tf.Tensor(\n",
            "[[131.  84.]\n",
            " [132.  80.]\n",
            " [132.  75.]\n",
            " ...\n",
            " [119.  73.]\n",
            " [114.  88.]\n",
            " [115.  85.]], shape=(120012, 2), dtype=float64)\n",
            "tf.Tensor(\n",
            "[[37.          1.         95.99215143 66.         36.61365023]\n",
            " [50.          1.         99.18077804 96.         36.96347701]\n",
            " [82.          1.         99.5009006  90.         37.08866965]\n",
            " ...\n",
            " [69.          0.         98.72763071 98.         37.31797986]\n",
            " [18.          0.         96.83673517 79.         36.76778201]\n",
            " [22.          1.         99.31742885 97.         36.04141329]], shape=(40004, 5), dtype=float64)\n",
            "tf.Tensor(\n",
            "[[114.  70.]\n",
            " [111.  78.]\n",
            " [131.  77.]\n",
            " ...\n",
            " [125.  83.]\n",
            " [134.  78.]\n",
            " [124.  83.]], shape=(40004, 2), dtype=float64)\n",
            "tf.Tensor(\n",
            "[[36.          0.         99.84785561 65.         37.09688165]\n",
            " [29.          1.         99.82055969 79.         37.06118408]\n",
            " [71.          0.         97.12098189 80.         36.74581493]\n",
            " ...\n",
            " [29.          0.         97.41173944 86.         36.89591688]\n",
            " [53.          0.         99.06424032 81.         37.05988065]\n",
            " [44.          0.         95.74273601 82.         36.06510427]], shape=(40004, 5), dtype=float64)\n",
            "tf.Tensor(\n",
            "[[132.  83.]\n",
            " [123.  84.]\n",
            " [132.  83.]\n",
            " ...\n",
            " [110.  72.]\n",
            " [126.  85.]\n",
            " [123.  70.]], shape=(40004, 2), dtype=float64)\n"
          ]
        }
      ],
      "source": [
        "# Convert the pandas DataFrame to a TensorFlow constant and shuffle it\n",
        "dataset_tf = tf.constant(dataset_csv)\n",
        "dataset_tf = tf.random.shuffle(dataset_tf)\n",
        "\n",
        "# Separate features (X) and labels (Y)\n",
        "# X includes 'age', 'gender', 'spo2', 'bpm', 'temp'\n",
        "# Y includes 'sbp', 'dbp'\n",
        "X = dataset_tf[:, 0:5]\n",
        "Y = dataset_tf[:, 5:]\n",
        "\n",
        "# Define the total number of samples\n",
        "N = dataset_tf.shape[0]\n",
        "\n",
        "# Define the ratios for training, validation, and testing datasets\n",
        "TRAIN_RATIO = 0.6\n",
        "VAL_RATIO = 0.2\n",
        "TEST_RATIO = 0.2\n",
        "\n",
        "# Split the dataset into training, validation, and testing sets\n",
        "X_train = X[:int(N*TRAIN_RATIO), :]\n",
        "Y_train = Y[:int(N*TRAIN_RATIO), :]\n",
        "X_val = X[int(N*TRAIN_RATIO):int(N*(TRAIN_RATIO+VAL_RATIO)), :]\n",
        "Y_val = Y[int(N*TRAIN_RATIO):int(N*(TRAIN_RATIO+VAL_RATIO)), :]\n",
        "X_test = X[int(N*(TRAIN_RATIO+VAL_RATIO)):, :]\n",
        "Y_test = Y[int(N*(TRAIN_RATIO+VAL_RATIO)):, :]\n",
        "\n",
        "# Create TensorFlow datasets for training, validation, and testing\n",
        "# Use shuffle with a larger buffer size for better randomization\n",
        "# Batch the datasets and prefetch for optimized performance\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=N).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
        "val_dataset = val_dataset.shuffle(buffer_size=N).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
        "test_dataset = test_dataset.shuffle(buffer_size=N).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Print the shapes of the split datasets for verification\n",
        "print(X_train)\n",
        "print(Y_train)\n",
        "print(X_val)\n",
        "print(Y_val)\n",
        "print(X_test)\n",
        "print(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm5DO98w9oeq"
      },
      "outputs": [],
      "source": [
        "# Initialize the Normalization layer\n",
        "normalizer = Normalization()\n",
        "# Adapt the normalizer to the training data to learn its mean and variance\n",
        "normalizer.adapt(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "nqxSmo6L9xlo",
        "outputId": "ccf5bf1b-8440-492a-df80-4a16a2dacc9e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ normalization_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">840</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">820</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ normalization_3 (\u001b[38;5;33mNormalization\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │           \u001b[38;5;34m840\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense3 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m820\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m42\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,833</span> (7.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,833\u001b[0m (7.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,822</span> (7.12 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,822\u001b[0m (7.12 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> (48.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11\u001b[0m (48.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the input layer with 5 features\n",
        "input = Input(shape = (5,))\n",
        "# Define the Normalization layer (Note: The `normalizer` variable was already adapted in a previous cell, so it should be used directly here if normalization is intended as part of the model)\n",
        "# For now, this line will create a new Normalization layer instance, which will not have been adapted.\n",
        "# If the adapted 'normalizer' from cell vm5DO98w9oeq is to be used, it should be passed here.\n",
        "normalizer_layer = Normalization()\n",
        "normalizer_layer.adapt(X_train) # Adapt the new normalizer to the training data\n",
        "x = normalizer_layer(input) # Apply normalization as the first step in the model\n",
        "\n",
        "# Add hidden dense layers with ReLU activation\n",
        "x = Dense(20, name = 'dense1', activation='relu')(x)\n",
        "x = Dense(40, name = 'dense2', activation='relu')(x)\n",
        "x = Dense(20, name = 'dense3', activation='relu')(x)\n",
        "\n",
        "# Output layer with 2 units (for sbp and dbp) and linear activation (default for regression)\n",
        "output = Dense(2)(x)\n",
        "\n",
        "# Create the Keras model using the Functional API\n",
        "model = Model(inputs = input ,outputs = output)\n",
        "\n",
        "# Compile the model with Mean Squared Error (mse) loss, Adam optimizer, and Root Mean Squared Error (rmse) metric\n",
        "model.compile(loss = 'mse', optimizer = 'adam', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ck3jwxo97E9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7GrRSHu-EpD",
        "outputId": "f54d801e-251b-4726-d8f5-c87eca97349c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 1662.0706 - root_mean_squared_error: 36.0182 - val_loss: 55.6908 - val_root_mean_squared_error: 7.4626\n",
            "Epoch 2/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 55.6291 - root_mean_squared_error: 7.4585 - val_loss: 54.5320 - val_root_mean_squared_error: 7.3846\n",
            "Epoch 3/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 55.0740 - root_mean_squared_error: 7.4211 - val_loss: 54.9502 - val_root_mean_squared_error: 7.4128\n",
            "Epoch 4/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9689 - root_mean_squared_error: 7.4141 - val_loss: 55.5969 - val_root_mean_squared_error: 7.4563\n",
            "Epoch 5/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9863 - root_mean_squared_error: 7.4152 - val_loss: 55.4741 - val_root_mean_squared_error: 7.4481\n",
            "Epoch 6/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 55.0339 - root_mean_squared_error: 7.4185 - val_loss: 54.4799 - val_root_mean_squared_error: 7.3810\n",
            "Epoch 7/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 55.0779 - root_mean_squared_error: 7.4214 - val_loss: 54.6864 - val_root_mean_squared_error: 7.3950\n",
            "Epoch 8/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9426 - root_mean_squared_error: 7.4123 - val_loss: 54.1982 - val_root_mean_squared_error: 7.3619\n",
            "Epoch 9/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.8961 - root_mean_squared_error: 7.4092 - val_loss: 54.9379 - val_root_mean_squared_error: 7.4120\n",
            "Epoch 10/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 55.0122 - root_mean_squared_error: 7.4170 - val_loss: 54.5430 - val_root_mean_squared_error: 7.3853\n",
            "Epoch 11/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9251 - root_mean_squared_error: 7.4111 - val_loss: 54.8607 - val_root_mean_squared_error: 7.4068\n",
            "Epoch 12/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9717 - root_mean_squared_error: 7.4143 - val_loss: 55.3554 - val_root_mean_squared_error: 7.4401\n",
            "Epoch 13/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9117 - root_mean_squared_error: 7.4102 - val_loss: 55.4200 - val_root_mean_squared_error: 7.4445\n",
            "Epoch 14/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7607 - root_mean_squared_error: 7.4000 - val_loss: 55.1749 - val_root_mean_squared_error: 7.4280\n",
            "Epoch 15/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9024 - root_mean_squared_error: 7.4096 - val_loss: 54.5540 - val_root_mean_squared_error: 7.3861\n",
            "Epoch 16/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9203 - root_mean_squared_error: 7.4108 - val_loss: 54.6617 - val_root_mean_squared_error: 7.3934\n",
            "Epoch 17/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9042 - root_mean_squared_error: 7.4097 - val_loss: 54.6799 - val_root_mean_squared_error: 7.3946\n",
            "Epoch 18/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9059 - root_mean_squared_error: 7.4098 - val_loss: 55.1853 - val_root_mean_squared_error: 7.4287\n",
            "Epoch 19/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9270 - root_mean_squared_error: 7.4113 - val_loss: 54.8638 - val_root_mean_squared_error: 7.4070\n",
            "Epoch 20/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 55.0834 - root_mean_squared_error: 7.4218 - val_loss: 54.7632 - val_root_mean_squared_error: 7.4002\n",
            "Epoch 21/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.8343 - root_mean_squared_error: 7.4050 - val_loss: 54.8517 - val_root_mean_squared_error: 7.4062\n",
            "Epoch 22/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7412 - root_mean_squared_error: 7.3987 - val_loss: 54.8325 - val_root_mean_squared_error: 7.4049\n",
            "Epoch 23/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7753 - root_mean_squared_error: 7.4010 - val_loss: 54.8840 - val_root_mean_squared_error: 7.4084\n",
            "Epoch 24/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9419 - root_mean_squared_error: 7.4122 - val_loss: 55.3198 - val_root_mean_squared_error: 7.4377\n",
            "Epoch 25/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.8305 - root_mean_squared_error: 7.4047 - val_loss: 54.5399 - val_root_mean_squared_error: 7.3851\n",
            "Epoch 26/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7918 - root_mean_squared_error: 7.4021 - val_loss: 54.7774 - val_root_mean_squared_error: 7.4012\n",
            "Epoch 27/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6919 - root_mean_squared_error: 7.3953 - val_loss: 54.3214 - val_root_mean_squared_error: 7.3703\n",
            "Epoch 28/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.8859 - root_mean_squared_error: 7.4084 - val_loss: 54.9797 - val_root_mean_squared_error: 7.4148\n",
            "Epoch 29/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7186 - root_mean_squared_error: 7.3972 - val_loss: 54.3383 - val_root_mean_squared_error: 7.3714\n",
            "Epoch 30/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.8188 - root_mean_squared_error: 7.4039 - val_loss: 54.2100 - val_root_mean_squared_error: 7.3627\n",
            "Epoch 31/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7014 - root_mean_squared_error: 7.3960 - val_loss: 54.2996 - val_root_mean_squared_error: 7.3688\n",
            "Epoch 32/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6990 - root_mean_squared_error: 7.3958 - val_loss: 54.1629 - val_root_mean_squared_error: 7.3595\n",
            "Epoch 33/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.8934 - root_mean_squared_error: 7.4090 - val_loss: 55.7614 - val_root_mean_squared_error: 7.4674\n",
            "Epoch 34/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7466 - root_mean_squared_error: 7.3991 - val_loss: 55.2444 - val_root_mean_squared_error: 7.4327\n",
            "Epoch 35/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9570 - root_mean_squared_error: 7.4133 - val_loss: 54.4949 - val_root_mean_squared_error: 7.3821\n",
            "Epoch 36/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7115 - root_mean_squared_error: 7.3967 - val_loss: 55.8373 - val_root_mean_squared_error: 7.4724\n",
            "Epoch 37/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7254 - root_mean_squared_error: 7.3976 - val_loss: 54.8125 - val_root_mean_squared_error: 7.4035\n",
            "Epoch 38/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.9558 - root_mean_squared_error: 7.4132 - val_loss: 55.0253 - val_root_mean_squared_error: 7.4179\n",
            "Epoch 39/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7797 - root_mean_squared_error: 7.4013 - val_loss: 54.3144 - val_root_mean_squared_error: 7.3698\n",
            "Epoch 40/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5316 - root_mean_squared_error: 7.3845 - val_loss: 54.2197 - val_root_mean_squared_error: 7.3634\n",
            "Epoch 41/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7730 - root_mean_squared_error: 7.4009 - val_loss: 54.4562 - val_root_mean_squared_error: 7.3794\n",
            "Epoch 42/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.8419 - root_mean_squared_error: 7.4055 - val_loss: 54.9568 - val_root_mean_squared_error: 7.4133\n",
            "Epoch 43/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6580 - root_mean_squared_error: 7.3931 - val_loss: 54.7295 - val_root_mean_squared_error: 7.3979\n",
            "Epoch 44/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.8333 - root_mean_squared_error: 7.4049 - val_loss: 54.8139 - val_root_mean_squared_error: 7.4036\n",
            "Epoch 45/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6875 - root_mean_squared_error: 7.3951 - val_loss: 54.4860 - val_root_mean_squared_error: 7.3815\n",
            "Epoch 46/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5302 - root_mean_squared_error: 7.3844 - val_loss: 54.1280 - val_root_mean_squared_error: 7.3572\n",
            "Epoch 47/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7426 - root_mean_squared_error: 7.3988 - val_loss: 55.6101 - val_root_mean_squared_error: 7.4572\n",
            "Epoch 48/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7025 - root_mean_squared_error: 7.3961 - val_loss: 54.3102 - val_root_mean_squared_error: 7.3695\n",
            "Epoch 49/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5686 - root_mean_squared_error: 7.3870 - val_loss: 54.7257 - val_root_mean_squared_error: 7.3977\n",
            "Epoch 50/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7066 - root_mean_squared_error: 7.3964 - val_loss: 54.5209 - val_root_mean_squared_error: 7.3838\n",
            "Epoch 51/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6826 - root_mean_squared_error: 7.3947 - val_loss: 54.3435 - val_root_mean_squared_error: 7.3718\n",
            "Epoch 52/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6582 - root_mean_squared_error: 7.3931 - val_loss: 54.1826 - val_root_mean_squared_error: 7.3609\n",
            "Epoch 53/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7482 - root_mean_squared_error: 7.3992 - val_loss: 54.5590 - val_root_mean_squared_error: 7.3864\n",
            "Epoch 54/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7153 - root_mean_squared_error: 7.3970 - val_loss: 54.2203 - val_root_mean_squared_error: 7.3634\n",
            "Epoch 55/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5333 - root_mean_squared_error: 7.3846 - val_loss: 54.5065 - val_root_mean_squared_error: 7.3828\n",
            "Epoch 56/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5529 - root_mean_squared_error: 7.3859 - val_loss: 54.2848 - val_root_mean_squared_error: 7.3678\n",
            "Epoch 57/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5524 - root_mean_squared_error: 7.3859 - val_loss: 56.1663 - val_root_mean_squared_error: 7.4944\n",
            "Epoch 58/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5922 - root_mean_squared_error: 7.3886 - val_loss: 54.4927 - val_root_mean_squared_error: 7.3819\n",
            "Epoch 59/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5970 - root_mean_squared_error: 7.3890 - val_loss: 54.3677 - val_root_mean_squared_error: 7.3734\n",
            "Epoch 60/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5446 - root_mean_squared_error: 7.3854 - val_loss: 54.2505 - val_root_mean_squared_error: 7.3655\n",
            "Epoch 61/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5528 - root_mean_squared_error: 7.3860 - val_loss: 54.6344 - val_root_mean_squared_error: 7.3915\n",
            "Epoch 62/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5546 - root_mean_squared_error: 7.3861 - val_loss: 55.2184 - val_root_mean_squared_error: 7.4309\n",
            "Epoch 63/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5521 - root_mean_squared_error: 7.3859 - val_loss: 54.9852 - val_root_mean_squared_error: 7.4152\n",
            "Epoch 64/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6931 - root_mean_squared_error: 7.3954 - val_loss: 54.2556 - val_root_mean_squared_error: 7.3658\n",
            "Epoch 65/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7212 - root_mean_squared_error: 7.3974 - val_loss: 54.6299 - val_root_mean_squared_error: 7.3912\n",
            "Epoch 66/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7061 - root_mean_squared_error: 7.3963 - val_loss: 54.4033 - val_root_mean_squared_error: 7.3759\n",
            "Epoch 67/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6770 - root_mean_squared_error: 7.3944 - val_loss: 55.2356 - val_root_mean_squared_error: 7.4321\n",
            "Epoch 68/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5107 - root_mean_squared_error: 7.3831 - val_loss: 54.5823 - val_root_mean_squared_error: 7.3880\n",
            "Epoch 69/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6160 - root_mean_squared_error: 7.3903 - val_loss: 54.1032 - val_root_mean_squared_error: 7.3555\n",
            "Epoch 70/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4919 - root_mean_squared_error: 7.3818 - val_loss: 54.1431 - val_root_mean_squared_error: 7.3582\n",
            "Epoch 71/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7500 - root_mean_squared_error: 7.3993 - val_loss: 54.2452 - val_root_mean_squared_error: 7.3651\n",
            "Epoch 72/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7100 - root_mean_squared_error: 7.3966 - val_loss: 54.5472 - val_root_mean_squared_error: 7.3856\n",
            "Epoch 73/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5290 - root_mean_squared_error: 7.3843 - val_loss: 54.2368 - val_root_mean_squared_error: 7.3646\n",
            "Epoch 74/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4683 - root_mean_squared_error: 7.3802 - val_loss: 54.1165 - val_root_mean_squared_error: 7.3564\n",
            "Epoch 75/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4304 - root_mean_squared_error: 7.3777 - val_loss: 54.6910 - val_root_mean_squared_error: 7.3953\n",
            "Epoch 76/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6108 - root_mean_squared_error: 7.3899 - val_loss: 54.4538 - val_root_mean_squared_error: 7.3793\n",
            "Epoch 77/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7733 - root_mean_squared_error: 7.4009 - val_loss: 54.2655 - val_root_mean_squared_error: 7.3665\n",
            "Epoch 78/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6241 - root_mean_squared_error: 7.3908 - val_loss: 54.4329 - val_root_mean_squared_error: 7.3779\n",
            "Epoch 79/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5060 - root_mean_squared_error: 7.3828 - val_loss: 54.1108 - val_root_mean_squared_error: 7.3560\n",
            "Epoch 80/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7550 - root_mean_squared_error: 7.3996 - val_loss: 54.3478 - val_root_mean_squared_error: 7.3721\n",
            "Epoch 81/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5336 - root_mean_squared_error: 7.3847 - val_loss: 54.3294 - val_root_mean_squared_error: 7.3709\n",
            "Epoch 82/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5175 - root_mean_squared_error: 7.3836 - val_loss: 55.1241 - val_root_mean_squared_error: 7.4246\n",
            "Epoch 83/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5885 - root_mean_squared_error: 7.3884 - val_loss: 54.3200 - val_root_mean_squared_error: 7.3702\n",
            "Epoch 84/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7047 - root_mean_squared_error: 7.3962 - val_loss: 54.3720 - val_root_mean_squared_error: 7.3737\n",
            "Epoch 85/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6307 - root_mean_squared_error: 7.3912 - val_loss: 54.0724 - val_root_mean_squared_error: 7.3534\n",
            "Epoch 86/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4514 - root_mean_squared_error: 7.3791 - val_loss: 54.2235 - val_root_mean_squared_error: 7.3637\n",
            "Epoch 87/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7256 - root_mean_squared_error: 7.3976 - val_loss: 54.2690 - val_root_mean_squared_error: 7.3667\n",
            "Epoch 88/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7322 - root_mean_squared_error: 7.3981 - val_loss: 54.7039 - val_root_mean_squared_error: 7.3962\n",
            "Epoch 89/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5783 - root_mean_squared_error: 7.3877 - val_loss: 54.1926 - val_root_mean_squared_error: 7.3616\n",
            "Epoch 90/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6459 - root_mean_squared_error: 7.3923 - val_loss: 54.6086 - val_root_mean_squared_error: 7.3898\n",
            "Epoch 91/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7316 - root_mean_squared_error: 7.3981 - val_loss: 54.3379 - val_root_mean_squared_error: 7.3714\n",
            "Epoch 92/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5685 - root_mean_squared_error: 7.3870 - val_loss: 54.3420 - val_root_mean_squared_error: 7.3717\n",
            "Epoch 93/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5226 - root_mean_squared_error: 7.3839 - val_loss: 54.3947 - val_root_mean_squared_error: 7.3753\n",
            "Epoch 94/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5750 - root_mean_squared_error: 7.3875 - val_loss: 54.1728 - val_root_mean_squared_error: 7.3602\n",
            "Epoch 95/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4193 - root_mean_squared_error: 7.3769 - val_loss: 54.1338 - val_root_mean_squared_error: 7.3576\n",
            "Epoch 96/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5139 - root_mean_squared_error: 7.3833 - val_loss: 54.6666 - val_root_mean_squared_error: 7.3937\n",
            "Epoch 97/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7543 - root_mean_squared_error: 7.3996 - val_loss: 55.5818 - val_root_mean_squared_error: 7.4553\n",
            "Epoch 98/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5394 - root_mean_squared_error: 7.3851 - val_loss: 54.7889 - val_root_mean_squared_error: 7.4019\n",
            "Epoch 99/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6022 - root_mean_squared_error: 7.3893 - val_loss: 54.4037 - val_root_mean_squared_error: 7.3759\n",
            "Epoch 100/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6371 - root_mean_squared_error: 7.3917 - val_loss: 54.1312 - val_root_mean_squared_error: 7.3574\n",
            "Epoch 101/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7980 - root_mean_squared_error: 7.4025 - val_loss: 54.9809 - val_root_mean_squared_error: 7.4149\n",
            "Epoch 102/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7077 - root_mean_squared_error: 7.3964 - val_loss: 54.4212 - val_root_mean_squared_error: 7.3771\n",
            "Epoch 103/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4653 - root_mean_squared_error: 7.3800 - val_loss: 54.6056 - val_root_mean_squared_error: 7.3896\n",
            "Epoch 104/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5820 - root_mean_squared_error: 7.3880 - val_loss: 54.0587 - val_root_mean_squared_error: 7.3525\n",
            "Epoch 105/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3807 - root_mean_squared_error: 7.3743 - val_loss: 54.3880 - val_root_mean_squared_error: 7.3748\n",
            "Epoch 106/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5130 - root_mean_squared_error: 7.3833 - val_loss: 54.2014 - val_root_mean_squared_error: 7.3622\n",
            "Epoch 107/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6439 - root_mean_squared_error: 7.3921 - val_loss: 54.0300 - val_root_mean_squared_error: 7.3505\n",
            "Epoch 108/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7116 - root_mean_squared_error: 7.3967 - val_loss: 54.0909 - val_root_mean_squared_error: 7.3547\n",
            "Epoch 109/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4897 - root_mean_squared_error: 7.3817 - val_loss: 54.5058 - val_root_mean_squared_error: 7.3828\n",
            "Epoch 110/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.6607 - root_mean_squared_error: 7.3933 - val_loss: 54.1957 - val_root_mean_squared_error: 7.3618\n",
            "Epoch 111/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3743 - root_mean_squared_error: 7.3739 - val_loss: 55.2135 - val_root_mean_squared_error: 7.4306\n",
            "Epoch 112/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5903 - root_mean_squared_error: 7.3885 - val_loss: 54.4143 - val_root_mean_squared_error: 7.3766\n",
            "Epoch 113/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4911 - root_mean_squared_error: 7.3818 - val_loss: 54.2531 - val_root_mean_squared_error: 7.3657\n",
            "Epoch 114/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4837 - root_mean_squared_error: 7.3813 - val_loss: 54.3076 - val_root_mean_squared_error: 7.3694\n",
            "Epoch 115/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5062 - root_mean_squared_error: 7.3828 - val_loss: 54.4041 - val_root_mean_squared_error: 7.3759\n",
            "Epoch 116/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2597 - root_mean_squared_error: 7.3661 - val_loss: 54.3854 - val_root_mean_squared_error: 7.3746\n",
            "Epoch 117/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5130 - root_mean_squared_error: 7.3832 - val_loss: 54.1574 - val_root_mean_squared_error: 7.3592\n",
            "Epoch 118/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4857 - root_mean_squared_error: 7.3814 - val_loss: 54.0630 - val_root_mean_squared_error: 7.3528\n",
            "Epoch 119/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3405 - root_mean_squared_error: 7.3716 - val_loss: 54.1501 - val_root_mean_squared_error: 7.3587\n",
            "Epoch 120/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4824 - root_mean_squared_error: 7.3812 - val_loss: 54.1714 - val_root_mean_squared_error: 7.3601\n",
            "Epoch 121/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3525 - root_mean_squared_error: 7.3724 - val_loss: 54.4208 - val_root_mean_squared_error: 7.3770\n",
            "Epoch 122/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5560 - root_mean_squared_error: 7.3862 - val_loss: 54.1474 - val_root_mean_squared_error: 7.3585\n",
            "Epoch 123/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2663 - root_mean_squared_error: 7.3665 - val_loss: 54.5656 - val_root_mean_squared_error: 7.3869\n",
            "Epoch 124/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5223 - root_mean_squared_error: 7.3839 - val_loss: 54.2396 - val_root_mean_squared_error: 7.3648\n",
            "Epoch 125/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4383 - root_mean_squared_error: 7.3782 - val_loss: 54.8320 - val_root_mean_squared_error: 7.4049\n",
            "Epoch 126/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3639 - root_mean_squared_error: 7.3732 - val_loss: 54.1804 - val_root_mean_squared_error: 7.3607\n",
            "Epoch 127/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3654 - root_mean_squared_error: 7.3733 - val_loss: 54.0973 - val_root_mean_squared_error: 7.3551\n",
            "Epoch 128/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3317 - root_mean_squared_error: 7.3710 - val_loss: 54.4008 - val_root_mean_squared_error: 7.3757\n",
            "Epoch 129/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5149 - root_mean_squared_error: 7.3834 - val_loss: 54.0906 - val_root_mean_squared_error: 7.3546\n",
            "Epoch 130/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4491 - root_mean_squared_error: 7.3789 - val_loss: 54.5627 - val_root_mean_squared_error: 7.3867\n",
            "Epoch 131/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5564 - root_mean_squared_error: 7.3862 - val_loss: 54.3949 - val_root_mean_squared_error: 7.3753\n",
            "Epoch 132/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3358 - root_mean_squared_error: 7.3713 - val_loss: 54.4131 - val_root_mean_squared_error: 7.3765\n",
            "Epoch 133/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3876 - root_mean_squared_error: 7.3748 - val_loss: 54.4857 - val_root_mean_squared_error: 7.3814\n",
            "Epoch 134/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.1725 - root_mean_squared_error: 7.3601 - val_loss: 54.5117 - val_root_mean_squared_error: 7.3832\n",
            "Epoch 135/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4112 - root_mean_squared_error: 7.3763 - val_loss: 54.5061 - val_root_mean_squared_error: 7.3828\n",
            "Epoch 136/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5732 - root_mean_squared_error: 7.3874 - val_loss: 55.6962 - val_root_mean_squared_error: 7.4630\n",
            "Epoch 137/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3729 - root_mean_squared_error: 7.3738 - val_loss: 54.3730 - val_root_mean_squared_error: 7.3738\n",
            "Epoch 138/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3824 - root_mean_squared_error: 7.3744 - val_loss: 54.1883 - val_root_mean_squared_error: 7.3613\n",
            "Epoch 139/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3606 - root_mean_squared_error: 7.3729 - val_loss: 54.2283 - val_root_mean_squared_error: 7.3640\n",
            "Epoch 140/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4338 - root_mean_squared_error: 7.3779 - val_loss: 54.2190 - val_root_mean_squared_error: 7.3634\n",
            "Epoch 141/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5295 - root_mean_squared_error: 7.3844 - val_loss: 54.3110 - val_root_mean_squared_error: 7.3696\n",
            "Epoch 142/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4080 - root_mean_squared_error: 7.3762 - val_loss: 54.4004 - val_root_mean_squared_error: 7.3757\n",
            "Epoch 143/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3375 - root_mean_squared_error: 7.3714 - val_loss: 54.3064 - val_root_mean_squared_error: 7.3693\n",
            "Epoch 144/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4263 - root_mean_squared_error: 7.3774 - val_loss: 54.3481 - val_root_mean_squared_error: 7.3721\n",
            "Epoch 145/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5613 - root_mean_squared_error: 7.3866 - val_loss: 54.1634 - val_root_mean_squared_error: 7.3596\n",
            "Epoch 146/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4371 - root_mean_squared_error: 7.3781 - val_loss: 54.4743 - val_root_mean_squared_error: 7.3807\n",
            "Epoch 147/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3180 - root_mean_squared_error: 7.3701 - val_loss: 54.5236 - val_root_mean_squared_error: 7.3840\n",
            "Epoch 148/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3696 - root_mean_squared_error: 7.3735 - val_loss: 54.1645 - val_root_mean_squared_error: 7.3597\n",
            "Epoch 149/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3553 - root_mean_squared_error: 7.3726 - val_loss: 54.5910 - val_root_mean_squared_error: 7.3886\n",
            "Epoch 150/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4582 - root_mean_squared_error: 7.3796 - val_loss: 54.1482 - val_root_mean_squared_error: 7.3585\n",
            "Epoch 151/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3387 - root_mean_squared_error: 7.3714 - val_loss: 55.3778 - val_root_mean_squared_error: 7.4416\n",
            "Epoch 152/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4239 - root_mean_squared_error: 7.3772 - val_loss: 54.1950 - val_root_mean_squared_error: 7.3617\n",
            "Epoch 153/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3364 - root_mean_squared_error: 7.3713 - val_loss: 54.1838 - val_root_mean_squared_error: 7.3610\n",
            "Epoch 154/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3029 - root_mean_squared_error: 7.3690 - val_loss: 54.1182 - val_root_mean_squared_error: 7.3565\n",
            "Epoch 155/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3597 - root_mean_squared_error: 7.3729 - val_loss: 54.8748 - val_root_mean_squared_error: 7.4078\n",
            "Epoch 156/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3509 - root_mean_squared_error: 7.3723 - val_loss: 54.5166 - val_root_mean_squared_error: 7.3835\n",
            "Epoch 157/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4741 - root_mean_squared_error: 7.3806 - val_loss: 54.1259 - val_root_mean_squared_error: 7.3570\n",
            "Epoch 158/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.7014 - root_mean_squared_error: 7.3960 - val_loss: 54.1618 - val_root_mean_squared_error: 7.3595\n",
            "Epoch 159/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4482 - root_mean_squared_error: 7.3789 - val_loss: 56.3672 - val_root_mean_squared_error: 7.5078\n",
            "Epoch 160/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3200 - root_mean_squared_error: 7.3702 - val_loss: 54.1107 - val_root_mean_squared_error: 7.3560\n",
            "Epoch 161/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3283 - root_mean_squared_error: 7.3707 - val_loss: 54.0465 - val_root_mean_squared_error: 7.3516\n",
            "Epoch 162/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4546 - root_mean_squared_error: 7.3793 - val_loss: 54.0200 - val_root_mean_squared_error: 7.3498\n",
            "Epoch 163/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2018 - root_mean_squared_error: 7.3621 - val_loss: 55.4624 - val_root_mean_squared_error: 7.4473\n",
            "Epoch 164/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4629 - root_mean_squared_error: 7.3799 - val_loss: 54.4033 - val_root_mean_squared_error: 7.3759\n",
            "Epoch 165/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.5040 - root_mean_squared_error: 7.3827 - val_loss: 54.0609 - val_root_mean_squared_error: 7.3526\n",
            "Epoch 166/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3360 - root_mean_squared_error: 7.3713 - val_loss: 54.2982 - val_root_mean_squared_error: 7.3687\n",
            "Epoch 167/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2967 - root_mean_squared_error: 7.3686 - val_loss: 54.3512 - val_root_mean_squared_error: 7.3723\n",
            "Epoch 168/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2860 - root_mean_squared_error: 7.3679 - val_loss: 55.1360 - val_root_mean_squared_error: 7.4254\n",
            "Epoch 169/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3578 - root_mean_squared_error: 7.3728 - val_loss: 54.1323 - val_root_mean_squared_error: 7.3575\n",
            "Epoch 170/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2934 - root_mean_squared_error: 7.3684 - val_loss: 54.0183 - val_root_mean_squared_error: 7.3497\n",
            "Epoch 171/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2931 - root_mean_squared_error: 7.3684 - val_loss: 54.3208 - val_root_mean_squared_error: 7.3703\n",
            "Epoch 172/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3530 - root_mean_squared_error: 7.3724 - val_loss: 54.1588 - val_root_mean_squared_error: 7.3593\n",
            "Epoch 173/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3800 - root_mean_squared_error: 7.3743 - val_loss: 54.4864 - val_root_mean_squared_error: 7.3815\n",
            "Epoch 174/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2900 - root_mean_squared_error: 7.3682 - val_loss: 54.4268 - val_root_mean_squared_error: 7.3775\n",
            "Epoch 175/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2767 - root_mean_squared_error: 7.3673 - val_loss: 54.1044 - val_root_mean_squared_error: 7.3556\n",
            "Epoch 176/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.1973 - root_mean_squared_error: 7.3619 - val_loss: 54.1543 - val_root_mean_squared_error: 7.3590\n",
            "Epoch 177/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4329 - root_mean_squared_error: 7.3778 - val_loss: 54.0582 - val_root_mean_squared_error: 7.3524\n",
            "Epoch 178/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2598 - root_mean_squared_error: 7.3661 - val_loss: 54.4717 - val_root_mean_squared_error: 7.3805\n",
            "Epoch 179/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2280 - root_mean_squared_error: 7.3639 - val_loss: 54.2845 - val_root_mean_squared_error: 7.3678\n",
            "Epoch 180/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.1604 - root_mean_squared_error: 7.3594 - val_loss: 54.9372 - val_root_mean_squared_error: 7.4120\n",
            "Epoch 181/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3541 - root_mean_squared_error: 7.3725 - val_loss: 54.4712 - val_root_mean_squared_error: 7.3805\n",
            "Epoch 182/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4056 - root_mean_squared_error: 7.3760 - val_loss: 54.1085 - val_root_mean_squared_error: 7.3558\n",
            "Epoch 183/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2365 - root_mean_squared_error: 7.3645 - val_loss: 54.3137 - val_root_mean_squared_error: 7.3698\n",
            "Epoch 184/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4651 - root_mean_squared_error: 7.3800 - val_loss: 54.1131 - val_root_mean_squared_error: 7.3562\n",
            "Epoch 185/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2970 - root_mean_squared_error: 7.3686 - val_loss: 54.5636 - val_root_mean_squared_error: 7.3867\n",
            "Epoch 186/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.0848 - root_mean_squared_error: 7.3542 - val_loss: 54.8055 - val_root_mean_squared_error: 7.4031\n",
            "Epoch 187/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3032 - root_mean_squared_error: 7.3691 - val_loss: 54.2652 - val_root_mean_squared_error: 7.3665\n",
            "Epoch 188/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2236 - root_mean_squared_error: 7.3636 - val_loss: 54.2654 - val_root_mean_squared_error: 7.3665\n",
            "Epoch 189/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3635 - root_mean_squared_error: 7.3732 - val_loss: 54.1807 - val_root_mean_squared_error: 7.3608\n",
            "Epoch 190/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3891 - root_mean_squared_error: 7.3749 - val_loss: 54.0717 - val_root_mean_squared_error: 7.3533\n",
            "Epoch 191/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.1625 - root_mean_squared_error: 7.3595 - val_loss: 54.0577 - val_root_mean_squared_error: 7.3524\n",
            "Epoch 192/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2914 - root_mean_squared_error: 7.3683 - val_loss: 55.1203 - val_root_mean_squared_error: 7.4243\n",
            "Epoch 193/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2801 - root_mean_squared_error: 7.3675 - val_loss: 54.1506 - val_root_mean_squared_error: 7.3587\n",
            "Epoch 194/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.2253 - root_mean_squared_error: 7.3637 - val_loss: 54.7624 - val_root_mean_squared_error: 7.4002\n",
            "Epoch 195/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3205 - root_mean_squared_error: 7.3702 - val_loss: 54.5622 - val_root_mean_squared_error: 7.3866\n",
            "Epoch 196/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.1492 - root_mean_squared_error: 7.3586 - val_loss: 54.0715 - val_root_mean_squared_error: 7.3533\n",
            "Epoch 197/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4087 - root_mean_squared_error: 7.3762 - val_loss: 54.4329 - val_root_mean_squared_error: 7.3779\n",
            "Epoch 198/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.0810 - root_mean_squared_error: 7.3540 - val_loss: 54.1122 - val_root_mean_squared_error: 7.3561\n",
            "Epoch 199/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.4360 - root_mean_squared_error: 7.3781 - val_loss: 54.1500 - val_root_mean_squared_error: 7.3587\n",
            "Epoch 200/200\n",
            "\u001b[1m3751/3751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 54.3133 - root_mean_squared_error: 7.3697 - val_loss: 54.2229 - val_root_mean_squared_error: 7.3636\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ff2187be450>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model using the training dataset, validating with the validation dataset\n",
        "# The model will be trained for 200 epochs, and training progress will be shown verbosely.\n",
        "model.fit(train_dataset, validation_data=val_dataset, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDXdzDuCCJxV"
      },
      "outputs": [],
      "source": [
        "model.save(\"model1.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm8GxoT2Ca4p",
        "outputId": "41f21e7e-c4ea-4da1-9799-72ff5c866631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 55.1761 - root_mean_squared_error: 7.4280\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[55.188114166259766, 7.42887020111084]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test, Y_test, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "jk44RPmJCkpB",
        "outputId": "b47aab76-8bd0-4f5c-912d-859e23567706"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ normalization_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,020</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ normalization_1 (\u001b[38;5;33mNormalization\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m2,550\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense3 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m1,020\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m42\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,923</span> (15.33 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,923\u001b[0m (15.33 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,912</span> (15.28 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,912\u001b[0m (15.28 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> (48.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11\u001b[0m (48.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input = Input(shape = (5,))\n",
        "normalizer = Normalization()\n",
        "# norm = tf.keras.layers.preprocessing.Normalization()\n",
        "normalizer.adapt(X_train)\n",
        "x = normalizer(input)\n",
        "x = Dense(50, name = 'dense1', activation=\"relu\")(x)\n",
        "x = Dense(50, name = 'dense2', activation=\"relu\")(x)\n",
        "x = Dense(20, name = 'dense3', activation=\"relu\")(x)\n",
        "output = Dense(2, activation=\"relu\")(x)\n",
        "model = Model(inputs = input ,outputs = output)\n",
        "model.compile(loss = 'mse', optimizer = Adam(learning_rate=0.1), metrics=[RootMeanSquaredError()])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d0erHHaC1eX",
        "outputId": "d76c2e47-8c6f-4c77-e56c-82b7abb7c22e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1015/1015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 558.4937 - root_mean_squared_error: 20.4865 - val_loss: nan - val_root_mean_squared_error: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m1015/1015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 78.2362 - root_mean_squared_error: 8.8385 - val_loss: nan - val_root_mean_squared_error: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m1015/1015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 60.2361 - root_mean_squared_error: 7.7598 - val_loss: nan - val_root_mean_squared_error: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m1015/1015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 61.1936 - root_mean_squared_error: 7.8156 - val_loss: nan - val_root_mean_squared_error: nan\n",
            "Epoch 5/10\n",
            "\u001b[1m1015/1015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 60.8469 - root_mean_squared_error: 7.7952 - val_loss: nan - val_root_mean_squared_error: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m1015/1015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 59.6748 - root_mean_squared_error: 7.7227 - val_loss: nan - val_root_mean_squared_error: nan\n",
            "Epoch 7/10\n",
            "\u001b[1m1015/1015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 57.9723 - root_mean_squared_error: 7.6122 - val_loss: nan - val_root_mean_squared_error: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m1015/1015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 57.0112 - root_mean_squared_error: 7.5504 - val_loss: nan - val_root_mean_squared_error: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m1015/1015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 57.5675 - root_mean_squared_error: 7.5855 - val_loss: nan - val_root_mean_squared_error: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m1015/1015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 57.5251 - root_mean_squared_error: 7.5828 - val_loss: nan - val_root_mean_squared_error: nan\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ff2187a6a20>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_dataset, validation_data=val_dataset, epochs=10, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "JTLqyP_FDJLv",
        "outputId": "8285bb43-bfc2-47cb-fda0-ca3d4339c43e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 4000x2000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sbp_pred = model.predict(X_test)[:, 1][500:600]\n",
        "ind = np.arange(100)\n",
        "plt.figure(figsize=(40, 20))\n",
        "width = 0.4\n",
        "plt.bar(ind, sbp_pred, width)\n",
        "plt.bar(ind+width, Y_test[:, 1][500:600], width)\n",
        "plt.show()\n",
        "model.save(\"model2.keras\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "julia 1.11",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
